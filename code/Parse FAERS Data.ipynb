{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <span style=\"color:red\">This notebook takes a very long time to run! Do not re-run unless REALLY necessary!</span>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Parse FAERS Data to Spreadsheets\n",
    "#### *(so that this piece of code does not need to be run again... ever... ;-) )*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import glob\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "FAERS is the FDA Adverse Event Reporting System. Adverse effects reported during different time periods can be downloaded as ASCII-formatted relational databases. Data from each time period are stored in their own subdirectories. For example, the subdirectory `faers_ascii_2014q2` contains a couple of documentation files and a subdirectory `ascii`, and in `ascii` there are several databases saved as `????14Q2.txt`.\n",
    "\n",
    "The code digs into these subdirectories to read the data. All data is merged into one (VERY!) big dataframe. There is a massive amount of data, so creating this dataframe can be very time consuming."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "root_dir = \"/Users/gogrean/Documents/Insight_Fellowship/Research/Mental_Health/NHANES_Survey/\"\n",
    "os.chdir(root_dir)\n",
    "faers_data_dir = \"data/FAERS/\"\n",
    "faers_data_subdirs = [d[0] for d in os.walk(faers_data_dir) if d[0][-5:]=='ascii']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda/lib/python3.5/site-packages/IPython/core/interactiveshell.py:2723: DtypeWarning: Columns (11,14,15,16) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  interactivity=interactivity, compiler=compiler, result=result)\n",
      "/anaconda/lib/python3.5/site-packages/IPython/core/interactiveshell.py:2723: DtypeWarning: Columns (14) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  interactivity=interactivity, compiler=compiler, result=result)\n",
      "/anaconda/lib/python3.5/site-packages/IPython/core/interactiveshell.py:2723: DtypeWarning: Columns (11,14) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  interactivity=interactivity, compiler=compiler, result=result)\n",
      "/anaconda/lib/python3.5/site-packages/IPython/core/interactiveshell.py:2723: DtypeWarning: Columns (13,14) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  interactivity=interactivity, compiler=compiler, result=result)\n",
      "/anaconda/lib/python3.5/site-packages/IPython/core/interactiveshell.py:2723: DtypeWarning: Columns (14,15) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  interactivity=interactivity, compiler=compiler, result=result)\n",
      "/anaconda/lib/python3.5/site-packages/IPython/core/interactiveshell.py:2723: DtypeWarning: Columns (14,15,16) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  interactivity=interactivity, compiler=compiler, result=result)\n",
      "/anaconda/lib/python3.5/site-packages/IPython/core/interactiveshell.py:2723: DtypeWarning: Columns (14,16) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  interactivity=interactivity, compiler=compiler, result=result)\n"
     ]
    }
   ],
   "source": [
    "df_drugs_list = []\n",
    "df_reactions_list = []\n",
    "for d in faers_data_subdirs:\n",
    "    os.chdir(root_dir + d)\n",
    "    for fname_drugs, fname_reactions in zip(glob.glob(\"DRUG*.txt\"),glob.glob(\"REAC*.txt\")):\n",
    "        with open(fname_drugs, 'r') as f:\n",
    "            df_drugs_list.append(pd.read_table(f, sep='$'))\n",
    "        with open(fname_reactions, 'r') as f:\n",
    "            df_reactions_list.append(pd.read_table(f, sep='$'))\n",
    "df_drugs = pd.concat(df_drugs_list, ignore_index=True)\n",
    "df_reactions = pd.concat(df_reactions_list, ignore_index=True)\n",
    "\n",
    "# drop a few columns in a desperate attempt to speed things up\n",
    "df_drugs.drop(labels=['cum_dose_chr', 'cum_dose_unit', 'dechal', 'dose_amt',\n",
    "                      'dose_form', 'dose_freq', 'dose_unit', 'dose_vbm', 'drug_seq', \n",
    "                      'exp_dt', 'lot_num', 'nda_num', 'rechal', 'role_cod', 'route', 'val_vbm'],\n",
    "              axis=1, inplace=True)\n",
    "df_reactions.drop(labels=['drug_rec_act'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Summary of the df_drugs dataframe...\n",
      "\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 14884310 entries, 0 to 14884309\n",
      "Data columns (total 4 columns):\n",
      "caseid       int64\n",
      "drugname     object\n",
      "primaryid    int64\n",
      "prod_ai      object\n",
      "dtypes: int64(2), object(2)\n",
      "memory usage: 567.8+ MB\n",
      "None\n",
      "\n",
      "\n",
      "Summary of the df_reactions dataframe...\n",
      "\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 12618453 entries, 0 to 12618452\n",
      "Data columns (total 3 columns):\n",
      "caseid       int64\n",
      "primaryid    int64\n",
      "pt           object\n",
      "dtypes: int64(2), object(1)\n",
      "memory usage: 385.1+ MB\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "# just making a point that handling these takes time...\n",
    "print('Summary of the df_drugs dataframe...\\n')\n",
    "print(df_drugs.info())\n",
    "print('\\n\\nSummary of the df_reactions dataframe...\\n')\n",
    "print(df_reactions.info())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since I only care about drugs used to treat psychiatric conditions, I exclude all the other rows. This makes future handling of the dataframes a little quicker. To do this easier, I check the generic drug names against entries in `brand_to_generic_drug_names.csv`. Some of the generic names are slightly different, with the ones in the FDA database being typically more precise. For simplicity though, I changed all the generic drug names to match the simpler name that I have in my file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-112-795250218291>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     21\u001b[0m             \u001b[0msimpler_chems\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mchem\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m     \u001b[0msimpler_chem_combo\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"; \"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msimpler_chems\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 23\u001b[0;31m     \u001b[0;32mif\u001b[0m \u001b[0msimpler_chem_combo\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mgeneric_drug_names\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     24\u001b[0m         \u001b[0mdf_drugs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mat\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'simple_name'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msimpler_chem_combo\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "os.chdir(root_dir + \"data/\")\n",
    "\n",
    "df_psycho_drugs = pd.read_csv(\"brand_to_generic_drug_names.csv\")\n",
    "generic_drug_names = df_psycho_drugs[\"Generic Name\"].unique()\n",
    "\n",
    "bad_indices = []\n",
    "for index, row in df_drugs.iterrows():\n",
    "    # TODO:\n",
    "    # In some cases, the generic name is N/A.\n",
    "    # Ignore for now since there is plenty of data, but this\n",
    "    # could be handled better in the future...\n",
    "    if isinstance(df_drugs.at[index,\"prod_ai\"], float):\n",
    "        bad_indices.append(index)\n",
    "        continue\n",
    "    # in the case of drugs that are combos of several others, the \n",
    "    # names of the individual drugs are separated by \"\\\"\n",
    "    chem_combo = df_drugs.at[index,\"prod_ai\"].strip().split(\"\\\\\")\n",
    "    simpler_chems = []\n",
    "    # Super hacky, but I only keep the first part of drug names that\n",
    "    # have multiple words. This is enough to match the drug names I \n",
    "    # have with the more precise ones in the FDA database. So something \n",
    "    # like \"DOXYCYCLINE HYCLATE\" will become \"DOXYCYCLINE\".\n",
    "    for chem in chem_combo:\n",
    "        if len(chem):\n",
    "            simpler_chems.append(chem.split()[0])\n",
    "    # For a match when it comes to composite drugs, I separate them by \n",
    "    # a \"; \", as I have them already in brand_to_generic_drug_names.csv.\n",
    "    simpler_chem_combo = \"; \".join(simpler_chems)\n",
    "    # And finally, if the name of the drug listed in a row is not in the \n",
    "    # list of drugs used to treat psychiatric conditions, that row will \n",
    "    # be ignored.\n",
    "    if simpler_chem_combo in generic_drug_names:\n",
    "        df_drugs.at[index, 'simple_name'] = simpler_chem_combo\n",
    "    else:\n",
    "        bad_indices.append(index)\n",
    "\n",
    "filtered_df_fda_drugs = df_drugs.drop(bad_indices).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Temporarily save the data, to avoid having to run the first bits of code \n",
    "# again in case this notebook needs to be re-run/debugged...\n",
    "os.chdir(root_dir + \"data/\")\n",
    "filtered_df_fda_drugs.to_csv(\"filtered_fda_drug_reports.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# And now load the data. Not needed if it is all run in one piece, but useful \n",
    "# if the notebook needs to be re-run/debugged in multiple iterations.\n",
    "os.chdir(root_dir + \"data/\")\n",
    "df_fda_drugs_reported = pd.read_csv(\"filtered_fda_drug_reports.csv\", header=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A list of the adverse effects reported for each entry ID is appended to the row with that ID in the newly-created dataframe. Just this part of the code takes about 2 hours to run..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2018-01-17 21:25:43\n",
      "Done with the first... 0\n",
      "Done with the first... 10000\n",
      "Done with the first... 20000\n",
      "Done with the first... 30000\n",
      "Done with the first... 40000\n",
      "Done with the first... 50000\n",
      "Done with the first... 60000\n",
      "Done with the first... 70000\n",
      "Done with the first... 80000\n",
      "Done with the first... 90000\n",
      "Done with the first... 100000\n",
      "Done with the first... 110000\n",
      "Done with the first... 120000\n",
      "Done with the first... 130000\n",
      "Done with the first... 140000\n",
      "Done with the first... 150000\n",
      "Done with the first... 160000\n",
      "Done with the first... 170000\n",
      "Done with the first... 180000\n",
      "Done with the first... 190000\n",
      "Done with the first... 200000\n",
      "Done with the first... 210000\n",
      "Done with the first... 220000\n",
      "Done with the first... 230000\n",
      "Done with the first... 240000\n",
      "Done with the first... 250000\n",
      "Done with the first... 260000\n",
      "Done with the first... 270000\n",
      "Done with the first... 280000\n",
      "Done with the first... 290000\n",
      "Done with the first... 300000\n",
      "Done with the first... 310000\n",
      "Done with the first... 320000\n",
      "Done with the first... 330000\n",
      "Done with the first... 340000\n",
      "Done with the first... 350000\n",
      "Done with the first... 360000\n",
      "Done with the first... 370000\n",
      "Done with the first... 380000\n",
      "Done with the first... 390000\n",
      "Done with the first... 400000\n",
      "Done with the first... 410000\n",
      "Done with the first... 420000\n",
      "Done with the first... 430000\n",
      "Done with the first... 440000\n",
      "Done with the first... 450000\n",
      "Done with the first... 460000\n",
      "Done with the first... 470000\n",
      "Done with the first... 480000\n",
      "Done with the first... 490000\n",
      "Done with the first... 500000\n",
      "Done with the first... 510000\n",
      "Done with the first... 520000\n",
      "Done with the first... 530000\n",
      "Done with the first... 540000\n",
      "Done with the first... 550000\n",
      "Done with the first... 560000\n",
      "Done with the first... 570000\n",
      "Done with the first... 580000\n",
      "Done with the first... 590000\n",
      "Done with the first... 600000\n",
      "Done with the first... 610000\n",
      "Done with the first... 620000\n",
      "Done with the first... 630000\n",
      "Done with the first... 640000\n",
      "Done with the first... 650000\n",
      "Done with the first... 660000\n",
      "Done with the first... 670000\n",
      "Done with the first... 680000\n",
      "Done with the first... 690000\n",
      "Done with the first... 700000\n",
      "Done with the first... 710000\n",
      "Done with the first... 720000\n",
      "Done with the first... 730000\n",
      "Done with the first... 740000\n",
      "Done with the first... 750000\n",
      "Done with the first... 760000\n",
      "Done with the first... 770000\n",
      "Done with the first... 780000\n",
      "Done with the first... 790000\n",
      "Done with the first... 800000\n",
      "Done with the first... 810000\n",
      "Done with the first... 820000\n",
      "Done with the first... 830000\n",
      "Done with the first... 840000\n",
      "Done with the first... 850000\n",
      "2018-01-17 23:26:42\n"
     ]
    }
   ],
   "source": [
    "from time import gmtime, strftime\n",
    "\n",
    "good_pids = list(df_fda_drugs_reported['primaryid'].unique())\n",
    "filtered_df_reactions = df_reactions[df_reactions.primaryid.isin(good_pids)]\n",
    "\n",
    "i = 0\n",
    "stored_effects_by_pid = {}\n",
    "\n",
    "print(strftime(\"%Y-%m-%d %H:%M:%S\", gmtime()))\n",
    "for index, row in df_fda_drugs_reported.iterrows():\n",
    "    pid = df_fda_drugs_reported.at[index, 'primaryid']\n",
    "    if pid not in stored_effects_by_pid:\n",
    "        effect = \"; \".join(df_reactions[df_reactions['primaryid']==row['primaryid']]['pt'])\n",
    "        df_fda_drugs_reported.at[index, 'adverse_effects'] = effect\n",
    "        stored_effects_by_pid[pid] = effect\n",
    "    else:\n",
    "        df_fda_drugs_reported.at[index, 'adverse_effects'] = stored_effects_by_pid[pid]\n",
    "    if index % 10000 == 0:\n",
    "        print('Done with the first... %i' %index)\n",
    "                                \n",
    "print(strftime(\"%Y-%m-%d %H:%M:%S\", gmtime()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# same reason as above to save the data...\n",
    "os.chdir(root_dir + \"data/\")\n",
    "df_fda_drugs_reported.to_csv(\"filtered_fda_drug_reports.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# and then reload it...\n",
    "os.chdir(root_dir + \"data/\")\n",
    "df_fda_drugs_reported = pd.read_csv(\"filtered_fda_drug_reports.csv\", header=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TODO: Function for each med. This was just to test the code..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('Drug interaction', 0.11835748792270531),\n",
       " ('Depression', 0.07971014492753623),\n",
       " ('Headache', 0.07729468599033816),\n",
       " ('Anxiety', 0.07004830917874397),\n",
       " ('Condition aggravated', 0.07004830917874397),\n",
       " ('Nausea', 0.06521739130434782),\n",
       " ('Atrioventricular septal defect', 0.06521739130434782),\n",
       " ('Weight increased', 0.06521739130434782),\n",
       " ('Vomiting', 0.06280193236714976),\n",
       " ('Dizziness', 0.06038647342995169),\n",
       " ('Dysmorphism', 0.06038647342995169),\n",
       " ('Suicidal ideation', 0.06038647342995169),\n",
       " ('Hypoaesthesia', 0.06038647342995169),\n",
       " ('Paraesthesia', 0.057971014492753624),\n",
       " ('Foetal exposure during pregnancy', 0.057971014492753624),\n",
       " ('Muscle spasms', 0.057971014492753624),\n",
       " ('Hot flush', 0.057971014492753624),\n",
       " ('Hyperhidrosis', 0.05555555555555555),\n",
       " ('Serotonin syndrome', 0.05555555555555555),\n",
       " ('Anger', 0.05314009661835749)]"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import collections\n",
    "\n",
    "parnate = df_fda_drugs_reported[df_fda_drugs_reported['simple_name'].str.lower() == 'tranylcypromine']\n",
    "\n",
    "a = [y for x in parnate['adverse_effects'].str.split(\"; \") for y in x]\n",
    "counter=collections.Counter(a)\n",
    "[(eff, p/len(counter)) for (eff, p) in counter.most_common(20)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('Drug ineffective', 0.14072494669509594),\n",
       " ('Drug interaction', 0.13859275053304904),\n",
       " ('Dizziness', 0.12153518123667377),\n",
       " ('Headache', 0.1044776119402985),\n",
       " ('Malaise', 0.1044776119402985),\n",
       " ('Serotonin syndrome', 0.1023454157782516),\n",
       " ('Anxiety', 0.09381663113006397),\n",
       " ('Fatigue', 0.09168443496801706),\n",
       " ('Hypertension', 0.07249466950959488),\n",
       " ('Intentional product misuse', 0.06609808102345416),\n",
       " ('Drug withdrawal syndrome', 0.06183368869936034),\n",
       " ('Fall', 0.057569296375266525),\n",
       " ('Product quality issue', 0.05543710021321962),\n",
       " ('Weight increased', 0.05543710021321962),\n",
       " ('Insomnia', 0.053304904051172705),\n",
       " ('Depression', 0.053304904051172705),\n",
       " ('Orthostatic hypotension', 0.053304904051172705),\n",
       " ('Balance disorder', 0.0511727078891258),\n",
       " ('Paraesthesia', 0.04904051172707889),\n",
       " ('Nervousness', 0.046908315565031986)]"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import collections\n",
    "\n",
    "nardil = df_fda_drugs_reported[df_fda_drugs_reported['simple_name'].str.lower() == 'phenelzine']\n",
    "\n",
    "a = [y for x in nardil['adverse_effects'].str.split(\"; \") for y in x]\n",
    "counter=collections.Counter(a)\n",
    "[(eff, p/len(counter)) for (eff, p) in counter.most_common(20)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
